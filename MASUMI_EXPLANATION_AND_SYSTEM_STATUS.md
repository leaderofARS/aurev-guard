# Masumi Explanation & System Status Check

## ğŸ¤– What is Masumi in AUREV Guard?

### Overview

**Masumi** is an **AI Agent Orchestration Framework** that acts as the "brain" of AUREV Guard. It's a middleware layer that coordinates multiple autonomous AI agents to work together on complex tasks.

### Masumi's Role in AUREV Guard

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MASUMI ORCHESTRATOR                      â”‚
â”‚              (The "Conductor" of AI Agents)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Masumi is NOT an AI model itself.
Masumi is a COORDINATION LAYER that:
  1. Discovers and registers AI agents
  2. Routes requests to the right agent
  3. Orchestrates multi-step workflows
  4. Tracks correlation IDs for debugging
  5. Handles errors and fallbacks
```

### What Masumi Does

#### 1. **Agent Discovery & Registration**
- **Location**: `masumi/orchestrator/config.yaml`
- **Purpose**: Defines which AI agents are available
- **Registered Agents**:
  ```yaml
  - payment (Port 8081)      â†’ Payment validation
  - compliance (Port 8082)   â†’ Compliance scoring
  - ai_model (Port 8083)     â†’ ML risk prediction
  ```

#### 2. **Workflow Orchestration**
- **Location**: `masumi/orchestrator/router.py`
- **Purpose**: Routes requests to appropriate agents based on workflow type
- **Supported Workflows**:
  - `ai_predict` â†’ AI risk prediction only
  - `settle` â†’ Payment settlement with risk assessment
  - `ai_train` â†’ Initialize ML model training
  - `ai_train_run` â†’ Execute training pipeline
  - `ai_config` â†’ Get/update training configuration
  - `data_quality` â†’ Assess data quality

#### 3. **Request Routing**
When Backend sends a request:
```
Backend â†’ POST /masumi/route
{
  "workflow": "ai_predict",
  "payload": { "features": {...} }
}
```

Masumi:
1. Identifies workflow type (`ai_predict`)
2. Looks up which agent handles it (`ai_model`)
3. Calls the agent: `POST http://localhost:8083/predict`
4. Returns the response to Backend

#### 4. **Error Handling & Fallbacks**
- If AI agent is unavailable, Masumi returns a mock prediction
- Tracks correlation IDs for debugging
- Logs all agent interactions

#### 5. **Agent Health Monitoring**
- Checks if agents are alive
- Reports agent status
- Enables/disables agents dynamically

---

## ğŸ”„ Complete Data Flow with Masumi

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Frontend Request                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User clicks "Analyze Wallet" in Frontend
    â†“
Frontend: POST /api/live-pipeline/start
{
  walletAddress: "addr_test1...",
  transactionId: "tx_123"
}
    â†“
Backend receives request
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Backend Processing                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Backend extracts features (18 dimensions)
    â†“
Backend: POST http://localhost:8080/masumi/route
{
  "workflow": "ai_predict",
  "payload": {
    "wallet_address": "addr_test1...",
    "features": {
      "tx_count_24h": 45,
      "total_received": 5000000,
      ...
    }
  }
}
    â†“
Masumi Orchestrator receives request
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Masumi Orchestration                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Masumi: route_request() function
    â†“
Identifies workflow: "ai_predict"
    â†“
Looks up agent: "ai_model" (from config.yaml)
    â†“
Agent endpoint: http://localhost:8083
    â†“
Masumi: POST http://localhost:8083/predict
{
  "wallet_address": "addr_test1...",
  "features": {...}
}
    â†“
AI Agent receives request
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: AI Agent Processing                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AI Agent: Loads ML models
  - Random Forest (risk scoring)
  - Isolation Forest (anomaly detection)
    â†“
AI Agent: Runs predictions
  - risk_score: 0.73
  - anomaly_score: 0.42
  - is_anomaly: true
    â†“
AI Agent: Returns response
{
  "risk_score": 0.73,
  "risk_label": "HIGH_RISK",
  "anomaly_score": 0.42,
  "is_anomaly": true,
  "confidence": 0.89
}
    â†“
Masumi receives AI Agent response
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: Response Back to Backend                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Masumi: Returns response to Backend
{
  "workflow": "ai_predict",
  "prediction": {
    "risk_score": 0.73,
    "risk_label": "HIGH_RISK",
    ...
  },
  "status": "success"
}
    â†“
Backend: Stores results in PipelineJob
    â†“
Backend: Returns to Frontend
{
  "jobId": "job_abc123",
  "status": "completed",
  "results": {...}
}
    â†“
Frontend: Displays results to user
```

---

## ğŸ¯ Why Masumi is Important

### Without Masumi (Direct Connection)
```
Backend â†’ AI Agent (direct)
Problems:
- Tight coupling (Backend must know AI Agent details)
- No workflow orchestration
- Difficult to add new agents
- No error handling/fallbacks
- Hard to scale
```

### With Masumi (Orchestrated)
```
Backend â†’ Masumi â†’ AI Agent
Benefits:
- Loose coupling (Backend doesn't know agent details)
- Workflow orchestration (multi-step processes)
- Easy to add new agents (just update config.yaml)
- Built-in error handling and fallbacks
- Scalable (add more agents easily)
- Correlation tracking for debugging
```

---

## ğŸ“Š Masumi Architecture

### Component Structure

```
masumi/
â”œâ”€â”€ orchestrator/
â”‚   â”œâ”€â”€ app.py              â†’ FastAPI main application
â”‚   â”œâ”€â”€ router.py           â†’ Workflow routing logic
â”‚   â”œâ”€â”€ registry.py        â†’ Agent registry (discovery)
â”‚   â”œâ”€â”€ config.yaml         â†’ Agent configuration
â”‚   â”œâ”€â”€ models.py           â†’ Pydantic data models
â”‚   â”œâ”€â”€ ai_training_params.py â†’ Training parameters
â”‚   â””â”€â”€ ai_model_agent.py  â†’ AI agent integration
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ ai_model/          â†’ AI ML models (port 8083)
â”‚   â”œâ”€â”€ compliance/         â†’ Compliance agent (port 8082)
â”‚   â””â”€â”€ payment/            â†’ Payment agent (port 8081)
â”‚
â””â”€â”€ common/
    â””â”€â”€ typing.py           â†’ Shared types (correlation_id)
```

### Key Files Explained

#### 1. `masumi/orchestrator/app.py`
- **Purpose**: Main FastAPI application
- **Endpoints**:
  - `GET /masumi/health` â†’ Health check
  - `GET /masumi/agents` â†’ List all agents
  - `POST /masumi/route` â†’ Route workflow requests
  - `POST /masumi/predict` â†’ Direct prediction
  - `GET /masumi/training/config` â†’ Get training config

#### 2. `masumi/orchestrator/router.py`
- **Purpose**: Workflow routing logic
- **Function**: `route_request(registry, body)`
- **Workflows**:
  - `ai_predict` â†’ Routes to `ai_model` agent
  - `settle` â†’ Routes to multiple agents (ai_model â†’ compliance â†’ payment)
  - `ai_train` â†’ Routes to `ai_model` agent for training

#### 3. `masumi/orchestrator/config.yaml`
- **Purpose**: Agent configuration
- **Defines**:
  - Agent names, endpoints, capabilities
  - Training parameters
  - Workflow definitions

#### 4. `masumi/orchestrator/registry.py`
- **Purpose**: Agent discovery and registration
- **Functions**:
  - `register(agent)` â†’ Register new agent
  - `get(name)` â†’ Get agent by name
  - `list()` â†’ List all agents

---

## ğŸ” Masumi Workflow Examples

### Example 1: AI Prediction Workflow

```python
# Backend sends:
POST /masumi/route
{
  "workflow": "ai_predict",
  "payload": {
    "wallet_address": "addr_test1...",
    "features": {
      "tx_count_24h": 45,
      "total_received": 5000000
    }
  }
}

# Masumi processes:
1. Identifies workflow: "ai_predict"
2. Looks up agent: "ai_model" (port 8083)
3. Calls: POST http://localhost:8083/predict
4. Returns: Prediction response
```

### Example 2: Payment Settlement Workflow

```python
# Backend sends:
POST /masumi/route
{
  "workflow": "settle",
  "payload": {
    "wallet_address": "addr_test1...",
    "amount": 1000000
  }
}

# Masumi processes:
1. Step 1: Call ai_model â†’ Get risk score
2. Step 2: If risk > 0.5, call compliance â†’ Get compliance score
3. Step 3: Call payment â†’ Validate settlement
4. Returns: Combined result from all steps
```

---

## ğŸ§ª Testing All Components

### System Status Check Script

I'll create a comprehensive test script that checks:
1. âœ… Frontend (Port 5173)
2. âœ… Backend (Port 5000)
3. âœ… Masumi Orchestrator (Port 8080)
4. âœ… AI Agent (Port 8083)
5. âœ… Live Pipeline Integration
6. âœ… End-to-End Flow

---

## ğŸ“ Summary: What Masumi Does

| Function | Description |
|----------|-------------|
| **Agent Discovery** | Finds and registers AI agents from config.yaml |
| **Request Routing** | Routes requests to the right agent based on workflow |
| **Workflow Orchestration** | Coordinates multi-step processes across agents |
| **Error Handling** | Provides fallbacks when agents are unavailable |
| **Correlation Tracking** | Tracks requests for debugging |
| **Health Monitoring** | Checks if agents are alive and responding |

**In Simple Terms**: Masumi is like a **smart router** that:
- Knows which AI agent can do what
- Routes requests to the right agent
- Coordinates multiple agents working together
- Handles errors gracefully
- Makes the system scalable and maintainable

---

## ğŸš€ How to Start All Services

### Terminal 1: Masumi Orchestrator
```powershell
cd C:\Users\Asus\Desktop\hackathon\aurevguard
python -m uvicorn masumi.orchestrator.app:app --reload --port 8080
```

### Terminal 2: Backend
```powershell
cd C:\Users\Asus\Desktop\hackathon\aurevguard\apps\backend
npm start
```

### Terminal 3: Frontend
```powershell
cd C:\Users\Asus\Desktop\hackathon\aurevguard\apps\frontend
npm run dev
```

### Terminal 4: AI Agent (Optional - if running separately)
```powershell
cd C:\Users\Asus\Desktop\hackathon\aurevguard\agents\ai_model
python -m uvicorn src.agent:app --reload --port 8083
```

---

## âœ… Verification Checklist

- [ ] Masumi Orchestrator running on port 8080
- [ ] Backend running on port 5000
- [ ] Frontend running on port 5173
- [ ] AI Agent accessible (via Masumi)
- [ ] All agents registered in Masumi
- [ ] Health endpoints responding
- [ ] Live pipeline can route through Masumi
- [ ] End-to-end flow working

---

**Masumi is the "glue" that makes all AI agents work together seamlessly!** ğŸ¤–âœ¨

